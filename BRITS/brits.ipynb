{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd2bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas<3.0.0 in /home/luis/code/baselines_temporal_data_inputation/.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/luis/code/baselines_temporal_data_inputation/.venv/lib/python3.12/site-packages (from pandas<3.0.0) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/luis/code/baselines_temporal_data_inputation/.venv/lib/python3.12/site-packages (from pandas<3.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luis/code/baselines_temporal_data_inputation/.venv/lib/python3.12/site-packages (from pandas<3.0.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luis/code/baselines_temporal_data_inputation/.venv/lib/python3.12/site-packages (from pandas<3.0.0) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/luis/code/baselines_temporal_data_inputation/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"pandas<3.0.0\"\n",
    "%pip install pypots benchpots pygrinder --upgrade\n",
    "%pip install scikit-learn   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3bb101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-10 18:30:23 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2026-02-10 18:30:23 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2026-02-10 18:30:23 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2026-02-10 18:30:23 [INFO]: Loaded successfully!\n",
      "/home/luis/code/baselines_temporal_data_inputation/.venv/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  X = X.groupby(\"RecordID\").apply(apply_func)\n",
      "2026-02-10 18:30:19 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. \n",
      "2026-02-10 18:30:19 [INFO]: 23029 values masked out in the val set as ground truth, take 10.04% of the original observed values\n",
      "2026-02-10 18:30:19 [INFO]: 28672 values masked out in the test set as ground truth, take 10.02% of the original observed values\n",
      "2026-02-10 18:30:19 [INFO]: Total sample number: 3997\n",
      "2026-02-10 18:30:19 [INFO]: Training set size: 2557 (63.97%)\n",
      "2026-02-10 18:30:19 [INFO]: Validation set size: 640 (16.01%)\n",
      "2026-02-10 18:30:19 [INFO]: Test set size: 800 (20.02%)\n",
      "2026-02-10 18:30:19 [INFO]: Number of steps: 48\n",
      "2026-02-10 18:30:19 [INFO]: Number of features: 37\n",
      "2026-02-10 18:30:19 [INFO]: Train set missing rate: 79.66%\n",
      "2026-02-10 18:30:19 [INFO]: Validating set missing rate: 81.85%\n",
      "2026-02-10 18:30:19 [INFO]: Test set missing rate: 81.87%\n",
      "2026-02-10 18:30:19 [INFO]: No given device, using default device: cpu\n",
      "2026-02-10 18:30:19 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2026-02-10 18:30:19 [INFO]: Using customized MAE as the training loss function.\n",
      "2026-02-10 18:30:19 [INFO]: Using customized MSE as the validation metric function.\n",
      "2026-02-10 18:30:19 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 729,584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2557, 48, 37)\n",
      "(640, 48, 37)\n",
      "Temos 79.7% valores faltantes em train_X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-10 18:30:34 [INFO]: Epoch 001 - training loss (MAE): 1.1009, validation MSE: 0.5520\n",
      "2026-02-10 18:30:47 [INFO]: Epoch 002 - training loss (MAE): 0.8623, validation MSE: 0.4785\n",
      "2026-02-10 18:31:07 [INFO]: Epoch 003 - training loss (MAE): 0.7962, validation MSE: 0.4392\n",
      "2026-02-10 18:31:13 [INFO]: Epoch 004 - training loss (MAE): 0.7528, validation MSE: 0.4130\n",
      "2026-02-10 18:31:34 [INFO]: Epoch 005 - training loss (MAE): 0.7226, validation MSE: 0.3994\n",
      "2026-02-10 18:31:36 [WARNING]: ‼️ Training got interrupted by the user. Exist now ...\n",
      "2026-02-10 18:31:36 [INFO]: Finished training. The best model is from epoch#5.\n",
      "2026-02-10 18:31:38 [INFO]: Successfully created the given path save_it_here\n",
      "2026-02-10 18:31:38 [INFO]: Saved the model to save_it_here/brits_physionet2012.pypots\n",
      "2026-02-10 18:31:38 [INFO]: Model loaded successfully from save_it_here/brits_physionet2012.pypots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.3091\n"
     ]
    }
   ],
   "source": [
    "# Importa bibliotecas necessárias para manipulação de dados e pré-processamento\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pygrinder import mcar, calc_missing_rate\n",
    "from benchpots.datasets import preprocess_physionet2012\n",
    "\n",
    "# Carrega e pré-processa o conjunto de dados PhysioNet 2012\n",
    "# subset='set-a' seleciona o subconjunto A do dataset\n",
    "# rate=0.1 adiciona artificialmente 10% de valores faltantes aos dados para teste\n",
    "data = preprocess_physionet2012(subset='set-a', rate=0.1)\n",
    "\n",
    "# Separa os dados em conjuntos de treino, validação e teste\n",
    "# Cada conjunto contém séries temporais com valores faltantes (originais + artificiais)\n",
    "train_X, val_X, test_X = data[\"train_X\"], data[\"val_X\"], data[\"test_X\"]\n",
    "\n",
    "# Exibe as dimensões dos dados: (n_amostras, n_passos_temporais, n_características)\n",
    "print(train_X.shape)\n",
    "print(val_X.shape)  # O número de amostras varia entre treino e validação, mas passos e características são iguais\n",
    "\n",
    "# Calcula e exibe a taxa de valores faltantes no conjunto de treino\n",
    "print(f\"Temos {calc_missing_rate(train_X):.1%} valores faltantes em train_X\")\n",
    "\n",
    "# Prepara o conjunto de treino: apenas as séries temporais incompletas são necessárias\n",
    "train_set = {\"X\": train_X}\n",
    "\n",
    "# Prepara o conjunto de validação: inclui tanto os dados incompletos quanto os originais completos\n",
    "# X_ori serve como ground truth para avaliar o desempenho do modelo e selecionar o melhor checkpoint\n",
    "val_set = {\n",
    "    \"X\": val_X,\n",
    "    \"X_ori\": data[\"val_X_ori\"],\n",
    "}\n",
    "\n",
    "# Prepara o conjunto de teste: contém apenas as séries temporais incompletas\n",
    "# O modelo irá imputar (preencher) os valores faltantes neste conjunto\n",
    "test_set = {\"X\": test_X}\n",
    "\n",
    "# Obtém os valores originais completos do conjunto de teste para avaliação final\n",
    "test_X_ori = data[\"test_X_ori\"]\n",
    "\n",
    "# Cria uma máscara que identifica os valores que foram artificialmente removidos\n",
    "# Esta máscara indica onde estão os valores que existem em X_ori mas foram removidos em test_X\n",
    "# Usa XOR (^) para encontrar posições que são faltantes em test_X mas presentes em test_X_ori\n",
    "indicating_mask = np.isnan(test_X) ^ np.isnan(test_X_ori)\n",
    "\n",
    "# Importa o modelo BRITS (Bidirectional Recurrent Imputation for Time Series)\n",
    "from pypots.imputation import BRITS\n",
    "from pypots.nn.functional import calc_mae\n",
    "\n",
    "# Configura e inicializa o modelo BRITS com os hiperparâmetros:\n",
    "# - n_steps: número de passos temporais na série\n",
    "# - n_features: número de características/variáveis em cada passo\n",
    "# - rnn_hidden_size: tamanho da camada oculta da RNN bidirecional\n",
    "# - epochs: número de épocas de treinamento\n",
    "brits = BRITS(\n",
    "    n_steps=train_X.shape[1],\n",
    "    n_features=train_X.shape[2],\n",
    "    rnn_hidden_size=256,\n",
    "    epochs=100,\n",
    ")\n",
    "\n",
    "# Treina o modelo usando o conjunto de treino e valida com o conjunto de validação\n",
    "# O modelo aprende a reconstruir valores faltantes através de RNNs bidirecionais\n",
    "brits.fit(train_set, val_set)\n",
    "\n",
    "# Usa o modelo treinado para imputar (preencher) todos os valores faltantes no conjunto de teste\n",
    "# Isso inclui tanto os valores originalmente faltantes quanto os artificialmente removidos\n",
    "imputation = brits.impute(test_set)\n",
    "\n",
    "# Calcula o erro absoluto médio (MAE) comparando os valores imputados com os valores verdadeiros\n",
    "# Avalia apenas os valores que foram artificialmente removidos (indicados pela máscara)\n",
    "mae = calc_mae(imputation, np.nan_to_num(test_X_ori), indicating_mask)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Salva o modelo treinado em arquivo para uso futuro\n",
    "# overwrite=True permite sobrescrever o arquivo se ele já existir\n",
    "brits.save(\"save_it_here/brits_physionet2012.pypots\", overwrite=True)\n",
    "\n",
    "# Recarrega o modelo salvo do arquivo\n",
    "# Útil para continuar o treinamento ou realizar novas imputações posteriormente\n",
    "brits.load(\"save_it_here/brits_physionet2012.pypots\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
